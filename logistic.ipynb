{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import pandas as pd\n",
    "import warnings\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.utils.class_weight import compute_class_weight\n",
    "from sklearn.metrics import accuracy_score\n",
    "import numpy as np\n",
    "from format_data import *"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Entraînement"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Importation et formattage des données"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMQ</th>\n",
       "      <th>U850</th>\n",
       "      <th>V850</th>\n",
       "      <th>UBOT</th>\n",
       "      <th>VBOT</th>\n",
       "      <th>QREFHT</th>\n",
       "      <th>PS</th>\n",
       "      <th>PSL</th>\n",
       "      <th>T200</th>\n",
       "      <th>T500</th>\n",
       "      <th>...</th>\n",
       "      <th>TMQ_WINDBOT_INTERACTION</th>\n",
       "      <th>QREFHT_TREFHT_INTERACTION</th>\n",
       "      <th>TMQ_SQUARE</th>\n",
       "      <th>WIND850_MAGNITUDE_SQUARE</th>\n",
       "      <th>WINDBOT_MAGNITUDE_SQUARE</th>\n",
       "      <th>TREFHT_SQUARE</th>\n",
       "      <th>MONTH_SIN</th>\n",
       "      <th>MONTH_COS</th>\n",
       "      <th>LAPSE_RATE</th>\n",
       "      <th>Label</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>14.278533</td>\n",
       "      <td>-3.173287</td>\n",
       "      <td>1.833835</td>\n",
       "      <td>-7.581432</td>\n",
       "      <td>3.399386</td>\n",
       "      <td>0.006412</td>\n",
       "      <td>103070.359400</td>\n",
       "      <td>103070.359400</td>\n",
       "      <td>214.141617</td>\n",
       "      <td>256.000519</td>\n",
       "      <td>...</td>\n",
       "      <td>118.635566</td>\n",
       "      <td>1.842325</td>\n",
       "      <td>203.876504</td>\n",
       "      <td>13.432702</td>\n",
       "      <td>69.033935</td>\n",
       "      <td>82562.958151</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.139530</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>44.269070</td>\n",
       "      <td>-3.000973</td>\n",
       "      <td>0.375796</td>\n",
       "      <td>-2.194901</td>\n",
       "      <td>-3.694045</td>\n",
       "      <td>0.017199</td>\n",
       "      <td>101155.218800</td>\n",
       "      <td>101155.218800</td>\n",
       "      <td>219.897949</td>\n",
       "      <td>266.757843</td>\n",
       "      <td>...</td>\n",
       "      <td>190.220828</td>\n",
       "      <td>5.165643</td>\n",
       "      <td>1959.750529</td>\n",
       "      <td>9.147060</td>\n",
       "      <td>18.463556</td>\n",
       "      <td>90207.229732</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.156200</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>29.716904</td>\n",
       "      <td>5.699519</td>\n",
       "      <td>-4.106040</td>\n",
       "      <td>3.079108</td>\n",
       "      <td>-2.678627</td>\n",
       "      <td>0.012480</td>\n",
       "      <td>101841.164100</td>\n",
       "      <td>101841.164100</td>\n",
       "      <td>215.238892</td>\n",
       "      <td>264.979614</td>\n",
       "      <td>...</td>\n",
       "      <td>121.279737</td>\n",
       "      <td>3.674712</td>\n",
       "      <td>883.094365</td>\n",
       "      <td>49.344087</td>\n",
       "      <td>16.655949</td>\n",
       "      <td>86705.590264</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.500000</td>\n",
       "      <td>0.165802</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>36.301456</td>\n",
       "      <td>-0.657589</td>\n",
       "      <td>-1.584453</td>\n",
       "      <td>-0.903698</td>\n",
       "      <td>-2.157597</td>\n",
       "      <td>0.017055</td>\n",
       "      <td>101450.968800</td>\n",
       "      <td>101450.968800</td>\n",
       "      <td>217.602081</td>\n",
       "      <td>267.198273</td>\n",
       "      <td>...</td>\n",
       "      <td>84.916650</td>\n",
       "      <td>5.140841</td>\n",
       "      <td>1317.795740</td>\n",
       "      <td>2.942915</td>\n",
       "      <td>5.471893</td>\n",
       "      <td>90860.960406</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>0.165321</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>29.445889</td>\n",
       "      <td>22.721797</td>\n",
       "      <td>-15.070397</td>\n",
       "      <td>1.895406</td>\n",
       "      <td>-7.071098</td>\n",
       "      <td>0.008437</td>\n",
       "      <td>101568.182752</td>\n",
       "      <td>101137.479833</td>\n",
       "      <td>215.028439</td>\n",
       "      <td>265.348473</td>\n",
       "      <td>...</td>\n",
       "      <td>215.565199</td>\n",
       "      <td>2.459911</td>\n",
       "      <td>867.060350</td>\n",
       "      <td>743.396917</td>\n",
       "      <td>53.592988</td>\n",
       "      <td>85008.390575</td>\n",
       "      <td>-0.500000</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.167733</td>\n",
       "      <td>2</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 53 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TMQ       U850       V850      UBOT      VBOT    QREFHT  \\\n",
       "0  14.278533  -3.173287   1.833835 -7.581432  3.399386  0.006412   \n",
       "1  44.269070  -3.000973   0.375796 -2.194901 -3.694045  0.017199   \n",
       "2  29.716904   5.699519  -4.106040  3.079108 -2.678627  0.012480   \n",
       "3  36.301456  -0.657589  -1.584453 -0.903698 -2.157597  0.017055   \n",
       "4  29.445889  22.721797 -15.070397  1.895406 -7.071098  0.008437   \n",
       "\n",
       "              PS            PSL        T200        T500  ...  \\\n",
       "0  103070.359400  103070.359400  214.141617  256.000519  ...   \n",
       "1  101155.218800  101155.218800  219.897949  266.757843  ...   \n",
       "2  101841.164100  101841.164100  215.238892  264.979614  ...   \n",
       "3  101450.968800  101450.968800  217.602081  267.198273  ...   \n",
       "4  101568.182752  101137.479833  215.028439  265.348473  ...   \n",
       "\n",
       "   TMQ_WINDBOT_INTERACTION  QREFHT_TREFHT_INTERACTION   TMQ_SQUARE  \\\n",
       "0               118.635566                   1.842325   203.876504   \n",
       "1               190.220828                   5.165643  1959.750529   \n",
       "2               121.279737                   3.674712   883.094365   \n",
       "3                84.916650                   5.140841  1317.795740   \n",
       "4               215.565199                   2.459911   867.060350   \n",
       "\n",
       "   WIND850_MAGNITUDE_SQUARE  WINDBOT_MAGNITUDE_SQUARE  TREFHT_SQUARE  \\\n",
       "0                 13.432702                 69.033935   82562.958151   \n",
       "1                  9.147060                 18.463556   90207.229732   \n",
       "2                 49.344087                 16.655949   86705.590264   \n",
       "3                  2.942915                  5.471893   90860.960406   \n",
       "4                743.396917                 53.592988   85008.390575   \n",
       "\n",
       "   MONTH_SIN  MONTH_COS  LAPSE_RATE  Label  \n",
       "0  -0.866025   0.500000    0.139530      0  \n",
       "1  -0.866025   0.500000    0.156200      0  \n",
       "2  -0.866025   0.500000    0.165802      2  \n",
       "3  -0.866025  -0.500000    0.165321      0  \n",
       "4  -0.500000  -0.866025    0.167733      2  \n",
       "\n",
       "[5 rows x 53 columns]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data = pd.read_csv(\"./data/GAN_train.csv\", index_col=0)\n",
    "train_data = format_data(train_data)\n",
    "train_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.sparse import csr_matrix, hstack\n",
    "\n",
    "class SoftmaxRegression:\n",
    "    def __init__(self, learning_rate=0.01, n_iterations=100000, regularization='L1', reg_coeff=0.01, weights=False, early_stopping=True, patience=10):\n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_iterations = n_iterations\n",
    "        self.regularization = regularization\n",
    "        self.reg_coeff = reg_coeff\n",
    "        self.use_weights = weights\n",
    "        self.sample_weights = None\n",
    "        self.theta = None\n",
    "        self.early_stopping = early_stopping\n",
    "        self.patience = patience\n",
    "\n",
    "    def softmax(self, scores):\n",
    "        exp_scores = np.exp(scores - np.max(scores, axis=1, keepdims=True))\n",
    "        return exp_scores / np.sum(exp_scores, axis=1, keepdims=True)\n",
    "\n",
    "    def compute_class_weights(self, y):\n",
    "        class_sample_counts = np.bincount(y)\n",
    "        weights = 1. / class_sample_counts\n",
    "        weights = weights / np.sum(weights) * len(np.unique(y))\n",
    "        return np.array([weights[label] for label in y])\n",
    "\n",
    "    def fit(self, X_train, y_train, X_val=None, y_val=None):\n",
    "        if not isinstance(X_train, csr_matrix):\n",
    "            X_train = csr_matrix(X_train)\n",
    "\n",
    "        bias_train = np.ones((X_train.shape[0], 1))\n",
    "        X_train_bias = np.hstack([bias_train, X_train.toarray()])\n",
    "\n",
    "        n_samples, n_features = X_train_bias.shape\n",
    "        n_classes = len(np.unique(y_train))\n",
    "\n",
    "        self.theta = 0.01 * np.random.randn(n_features, n_classes)\n",
    "\n",
    "        if self.use_weights:\n",
    "            self.sample_weights = self.compute_class_weights(y_train)\n",
    "        else:\n",
    "            self.sample_weights = np.ones(n_samples)\n",
    "\n",
    "        best_theta = None\n",
    "        best_val_accuracy = float('-inf')\n",
    "        no_improvement_count = 0\n",
    "\n",
    "        if self.early_stopping and X_val is not None and y_val is not None:\n",
    "            if not isinstance(X_val, csr_matrix):\n",
    "                X_val = csr_matrix(X_val)\n",
    "            bias_val = np.ones((X_val.shape[0], 1))\n",
    "            X_val_bias = np.hstack([bias_val, X_val.toarray()])\n",
    "\n",
    "        for i in range(self.n_iterations):\n",
    "            scores = X_train_bias.dot(self.theta)\n",
    "            probabilities = self.softmax(scores)\n",
    "\n",
    "            y_onehot = np.zeros(probabilities.shape)\n",
    "            y_onehot[np.arange(n_samples), y_train] = 1\n",
    "\n",
    "            gradient = - (X_train_bias.T.dot(self.sample_weights[:, np.newaxis] * (y_onehot - probabilities))) / np.sum(self.sample_weights)\n",
    "\n",
    "            if self.regularization == 'L2':\n",
    "                reg_theta = self.theta.copy()\n",
    "                reg_theta[0] = 0\n",
    "                gradient += self.reg_coeff * reg_theta\n",
    "            elif self.regularization == 'L1':\n",
    "                gradient += self.reg_coeff * np.sign(self.theta)\n",
    "\n",
    "            self.theta -= self.learning_rate * gradient\n",
    "\n",
    "            train_accuracy = self.score(X_train, y_train)\n",
    "            print(f\"Iteration {i}: Training accuracy: {train_accuracy:.4f}\", end=\"\")\n",
    "\n",
    "            if self.early_stopping and X_val is not None and y_val is not None:\n",
    "                val_accuracy = self.score(X_val, y_val)\n",
    "                print(f\", Validation accuracy: {val_accuracy:.4f}\", end=\"\")\n",
    "\n",
    "                if val_accuracy > best_val_accuracy:\n",
    "                    best_val_accuracy = val_accuracy\n",
    "                    best_theta = self.theta.copy()\n",
    "                    no_improvement_count = 0\n",
    "                else:\n",
    "                    no_improvement_count += 1\n",
    "\n",
    "                if no_improvement_count >= self.patience:\n",
    "                    print(f\"\\nEarly stopping after {i} iterations\")\n",
    "                    self.theta = best_theta\n",
    "                    val_accuracy = self.score(X_val, y_val)\n",
    "                    print(f\", Best validation accuracy: {val_accuracy:.4f}\", end=\"\")\n",
    "                    break\n",
    "\n",
    "            print(\"\")\n",
    "\n",
    "    def predict(self, X):\n",
    "        if not isinstance(X, csr_matrix):\n",
    "            X = csr_matrix(X)\n",
    "\n",
    "        bias = np.ones((X.shape[0], 1))\n",
    "        X_bias = np.hstack([bias, X.toarray()])\n",
    "\n",
    "        scores = X_bias.dot(self.theta)\n",
    "        predictions = np.argmax(scores, axis=1)\n",
    "        return predictions\n",
    "\n",
    "    def score(self, X, y):\n",
    "        predictions = self.predict(X)\n",
    "        accuracy = np.mean(predictions == y)\n",
    "        return accuracy"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [],
   "source": [
    "logisticRegression = SoftmaxRegression(\n",
    "learning_rate=0.00001, \n",
    "n_iterations=100000, \n",
    "regularization='L1',\n",
    "reg_coeff=0.05, \n",
    "weights=True,\n",
    "early_stopping=True,\n",
    "patience=100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [],
   "source": [
    "y = train_data[\"Label\"]\n",
    "X = train_data.drop(columns=[\"Label\"])\n",
    "\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.3, random_state=42, stratify=y)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 81,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration 0: Training accuracy: 0.4262, Validation accuracy: 0.4363\n",
      "Iteration 1: Training accuracy: 0.2086, Validation accuracy: 0.2098\n",
      "Iteration 2: Training accuracy: 0.6086, Validation accuracy: 0.6111\n",
      "Iteration 3: Training accuracy: 0.2230, Validation accuracy: 0.2243\n",
      "Iteration 4: Training accuracy: 0.1117, Validation accuracy: 0.1136\n",
      "Iteration 5: Training accuracy: 0.2165, Validation accuracy: 0.2184\n",
      "Iteration 6: Training accuracy: 0.5320, Validation accuracy: 0.5387\n",
      "Iteration 7: Training accuracy: 0.2345, Validation accuracy: 0.2345\n",
      "Iteration 8: Training accuracy: 0.0480, Validation accuracy: 0.0483\n",
      "Iteration 9: Training accuracy: 0.5794, Validation accuracy: 0.5848\n",
      "Iteration 10: Training accuracy: 0.1777, Validation accuracy: 0.1718\n",
      "Iteration 11: Training accuracy: 0.6829, Validation accuracy: 0.6840\n",
      "Iteration 12: Training accuracy: 0.1705, Validation accuracy: 0.1635\n",
      "Iteration 13: Training accuracy: 0.2305, Validation accuracy: 0.2279\n",
      "Iteration 14: Training accuracy: 0.0487, Validation accuracy: 0.0486\n",
      "Iteration 15: Training accuracy: 0.5518, Validation accuracy: 0.5575\n",
      "Iteration 16: Training accuracy: 0.2183, Validation accuracy: 0.2106\n",
      "Iteration 17: Training accuracy: 0.7184, Validation accuracy: 0.7202\n",
      "Iteration 18: Training accuracy: 0.0625, Validation accuracy: 0.0631\n",
      "Iteration 19: Training accuracy: 0.2197, Validation accuracy: 0.2221\n",
      "Iteration 20: Training accuracy: 0.1972, Validation accuracy: 0.1909\n",
      "Iteration 21: Training accuracy: 0.4505, Validation accuracy: 0.4489\n",
      "Iteration 22: Training accuracy: 0.2352, Validation accuracy: 0.2349\n",
      "Iteration 23: Training accuracy: 0.2734, Validation accuracy: 0.2696\n",
      "Iteration 24: Training accuracy: 0.6139, Validation accuracy: 0.6161\n",
      "Iteration 25: Training accuracy: 0.1994, Validation accuracy: 0.1923\n",
      "Iteration 26: Training accuracy: 0.6750, Validation accuracy: 0.6764\n",
      "Iteration 27: Training accuracy: 0.0514, Validation accuracy: 0.0526\n",
      "Iteration 28: Training accuracy: 0.2207, Validation accuracy: 0.2224\n",
      "Iteration 29: Training accuracy: 0.2614, Validation accuracy: 0.2537\n",
      "Iteration 30: Training accuracy: 0.5676, Validation accuracy: 0.5729\n",
      "Iteration 31: Training accuracy: 0.2349, Validation accuracy: 0.2348\n",
      "Iteration 32: Training accuracy: 0.0859, Validation accuracy: 0.0850\n",
      "Iteration 33: Training accuracy: 0.5893, Validation accuracy: 0.5933\n",
      "Iteration 34: Training accuracy: 0.2163, Validation accuracy: 0.2068\n",
      "Iteration 35: Training accuracy: 0.7037, Validation accuracy: 0.7007\n",
      "Iteration 36: Training accuracy: 0.1713, Validation accuracy: 0.1643\n",
      "Iteration 37: Training accuracy: 0.2362, Validation accuracy: 0.2340\n",
      "Iteration 38: Training accuracy: 0.0915, Validation accuracy: 0.0886\n",
      "Iteration 39: Training accuracy: 0.6283, Validation accuracy: 0.6373\n",
      "Iteration 40: Training accuracy: 0.0897, Validation accuracy: 0.0870\n",
      "Iteration 41: Training accuracy: 0.4837, Validation accuracy: 0.4877\n",
      "Iteration 42: Training accuracy: 0.3636, Validation accuracy: 0.3547\n",
      "Iteration 43: Training accuracy: 0.7163, Validation accuracy: 0.7162\n",
      "Iteration 44: Training accuracy: 0.0798, Validation accuracy: 0.0829\n",
      "Iteration 45: Training accuracy: 0.2195, Validation accuracy: 0.2220\n",
      "Iteration 46: Training accuracy: 0.1942, Validation accuracy: 0.1865\n",
      "Iteration 47: Training accuracy: 0.4858, Validation accuracy: 0.4858\n",
      "Iteration 48: Training accuracy: 0.2437, Validation accuracy: 0.2423\n",
      "Iteration 49: Training accuracy: 0.2545, Validation accuracy: 0.2557\n",
      "Iteration 50: Training accuracy: 0.5980, Validation accuracy: 0.6006\n",
      "Iteration 51: Training accuracy: 0.2236, Validation accuracy: 0.2146\n",
      "Iteration 52: Training accuracy: 0.6943, Validation accuracy: 0.6920\n",
      "Iteration 53: Training accuracy: 0.2005, Validation accuracy: 0.1967\n",
      "Iteration 54: Training accuracy: 0.1980, Validation accuracy: 0.1882\n",
      "Iteration 55: Training accuracy: 0.2293, Validation accuracy: 0.2301\n",
      "Iteration 56: Training accuracy: 0.4923, Validation accuracy: 0.4900\n",
      "Iteration 57: Training accuracy: 0.2900, Validation accuracy: 0.2865\n",
      "Iteration 58: Training accuracy: 0.2627, Validation accuracy: 0.2626\n",
      "Iteration 59: Training accuracy: 0.5880, Validation accuracy: 0.5926\n",
      "Iteration 60: Training accuracy: 0.2622, Validation accuracy: 0.2505\n",
      "Iteration 61: Training accuracy: 0.6681, Validation accuracy: 0.6673\n",
      "Iteration 62: Training accuracy: 0.2193, Validation accuracy: 0.2213\n",
      "Iteration 63: Training accuracy: 0.2649, Validation accuracy: 0.2596\n",
      "Iteration 64: Training accuracy: 0.2276, Validation accuracy: 0.2270\n",
      "Iteration 65: Training accuracy: 0.4887, Validation accuracy: 0.4841\n",
      "Iteration 66: Training accuracy: 0.2650, Validation accuracy: 0.2609\n",
      "Iteration 67: Training accuracy: 0.3107, Validation accuracy: 0.3108\n",
      "Iteration 68: Training accuracy: 0.5791, Validation accuracy: 0.5845\n",
      "Iteration 69: Training accuracy: 0.2523, Validation accuracy: 0.2396\n",
      "Iteration 70: Training accuracy: 0.6458, Validation accuracy: 0.6482\n",
      "Iteration 71: Training accuracy: 0.2294, Validation accuracy: 0.2293\n",
      "Iteration 72: Training accuracy: 0.3205, Validation accuracy: 0.3133\n",
      "Iteration 73: Training accuracy: 0.2295, Validation accuracy: 0.2277\n",
      "Iteration 74: Training accuracy: 0.5027, Validation accuracy: 0.5005\n",
      "Iteration 75: Training accuracy: 0.2562, Validation accuracy: 0.2529\n",
      "Iteration 76: Training accuracy: 0.2977, Validation accuracy: 0.2996\n",
      "Iteration 77: Training accuracy: 0.5789, Validation accuracy: 0.5840\n",
      "Iteration 78: Training accuracy: 0.2518, Validation accuracy: 0.2413\n",
      "Iteration 79: Training accuracy: 0.6391, Validation accuracy: 0.6400\n",
      "Iteration 80: Training accuracy: 0.2355, Validation accuracy: 0.2360\n",
      "Iteration 81: Training accuracy: 0.3438, Validation accuracy: 0.3372\n",
      "Iteration 82: Training accuracy: 0.2418, Validation accuracy: 0.2376\n",
      "Iteration 83: Training accuracy: 0.5309, Validation accuracy: 0.5356\n",
      "Iteration 84: Training accuracy: 0.2525, Validation accuracy: 0.2482\n",
      "Iteration 85: Training accuracy: 0.2348, Validation accuracy: 0.2326\n",
      "Iteration 86: Training accuracy: 0.5817, Validation accuracy: 0.5872\n",
      "Iteration 87: Training accuracy: 0.2632, Validation accuracy: 0.2516\n",
      "Iteration 88: Training accuracy: 0.6442, Validation accuracy: 0.6446\n",
      "Iteration 89: Training accuracy: 0.2374, Validation accuracy: 0.2393\n",
      "Iteration 90: Training accuracy: 0.3577, Validation accuracy: 0.3511\n",
      "Iteration 91: Training accuracy: 0.2422, Validation accuracy: 0.2395\n",
      "Iteration 92: Training accuracy: 0.5283, Validation accuracy: 0.5322\n",
      "Iteration 93: Training accuracy: 0.2584, Validation accuracy: 0.2543\n",
      "Iteration 94: Training accuracy: 0.2752, Validation accuracy: 0.2749\n",
      "Iteration 95: Training accuracy: 0.5819, Validation accuracy: 0.5870\n",
      "Iteration 96: Training accuracy: 0.2661, Validation accuracy: 0.2540\n",
      "Iteration 97: Training accuracy: 0.6458, Validation accuracy: 0.6467\n",
      "Iteration 98: Training accuracy: 0.2420, Validation accuracy: 0.2430\n",
      "Iteration 99: Training accuracy: 0.3702, Validation accuracy: 0.3657\n",
      "Iteration 100: Training accuracy: 0.2440, Validation accuracy: 0.2405\n",
      "Iteration 101: Training accuracy: 0.5287, Validation accuracy: 0.5319\n",
      "Iteration 102: Training accuracy: 0.2594, Validation accuracy: 0.2562\n",
      "Iteration 103: Training accuracy: 0.2860, Validation accuracy: 0.2866\n",
      "Iteration 104: Training accuracy: 0.5819, Validation accuracy: 0.5867\n",
      "Iteration 105: Training accuracy: 0.2671, Validation accuracy: 0.2546\n",
      "Iteration 106: Training accuracy: 0.6472, Validation accuracy: 0.6492\n",
      "Iteration 107: Training accuracy: 0.2487, Validation accuracy: 0.2484\n",
      "Iteration 108: Training accuracy: 0.3854, Validation accuracy: 0.3802\n",
      "Iteration 109: Training accuracy: 0.2456, Validation accuracy: 0.2405\n",
      "Iteration 110: Training accuracy: 0.5283, Validation accuracy: 0.5316\n",
      "Iteration 111: Training accuracy: 0.2615, Validation accuracy: 0.2574\n",
      "Iteration 112: Training accuracy: 0.3008, Validation accuracy: 0.3029\n",
      "Iteration 113: Training accuracy: 0.5817, Validation accuracy: 0.5858\n",
      "Iteration 114: Training accuracy: 0.2694, Validation accuracy: 0.2604\n",
      "Iteration 115: Training accuracy: 0.6486, Validation accuracy: 0.6503\n",
      "Iteration 116: Training accuracy: 0.2521, Validation accuracy: 0.2521\n",
      "Iteration 117: Training accuracy: 0.4006, Validation accuracy: 0.3952\n",
      "Early stopping after 117 iterations\n",
      ", Best validation accuracy: 0.7202"
     ]
    }
   ],
   "source": [
    "logisticRegression.fit(X_train, y_train, X_val, y_val)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>TMQ</th>\n",
       "      <th>U850</th>\n",
       "      <th>V850</th>\n",
       "      <th>UBOT</th>\n",
       "      <th>VBOT</th>\n",
       "      <th>QREFHT</th>\n",
       "      <th>PS</th>\n",
       "      <th>PSL</th>\n",
       "      <th>T200</th>\n",
       "      <th>T500</th>\n",
       "      <th>...</th>\n",
       "      <th>TMQ_WIND850_INTERACTION</th>\n",
       "      <th>TMQ_WINDBOT_INTERACTION</th>\n",
       "      <th>QREFHT_TREFHT_INTERACTION</th>\n",
       "      <th>TMQ_SQUARE</th>\n",
       "      <th>WIND850_MAGNITUDE_SQUARE</th>\n",
       "      <th>WINDBOT_MAGNITUDE_SQUARE</th>\n",
       "      <th>TREFHT_SQUARE</th>\n",
       "      <th>MONTH_SIN</th>\n",
       "      <th>MONTH_COS</th>\n",
       "      <th>LAPSE_RATE</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>25.907482</td>\n",
       "      <td>6.662070</td>\n",
       "      <td>-17.510447</td>\n",
       "      <td>-7.432653</td>\n",
       "      <td>-3.936030</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>101532.5391</td>\n",
       "      <td>101532.5391</td>\n",
       "      <td>213.092209</td>\n",
       "      <td>256.032043</td>\n",
       "      <td>...</td>\n",
       "      <td>485.375771</td>\n",
       "      <td>217.895122</td>\n",
       "      <td>3.081385</td>\n",
       "      <td>671.197631</td>\n",
       "      <td>350.998912</td>\n",
       "      <td>70.736668</td>\n",
       "      <td>84123.171146</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.143133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>25.907482</td>\n",
       "      <td>6.662070</td>\n",
       "      <td>-17.510447</td>\n",
       "      <td>-7.432653</td>\n",
       "      <td>-3.936030</td>\n",
       "      <td>0.010624</td>\n",
       "      <td>101532.5391</td>\n",
       "      <td>101532.5391</td>\n",
       "      <td>213.092209</td>\n",
       "      <td>256.032043</td>\n",
       "      <td>...</td>\n",
       "      <td>485.375771</td>\n",
       "      <td>217.895122</td>\n",
       "      <td>3.081385</td>\n",
       "      <td>671.197631</td>\n",
       "      <td>350.998912</td>\n",
       "      <td>70.736668</td>\n",
       "      <td>84123.171146</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.143133</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>27.019733</td>\n",
       "      <td>4.951319</td>\n",
       "      <td>-17.341263</td>\n",
       "      <td>-7.286631</td>\n",
       "      <td>-3.150316</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>101513.0234</td>\n",
       "      <td>101513.0234</td>\n",
       "      <td>213.161011</td>\n",
       "      <td>255.616837</td>\n",
       "      <td>...</td>\n",
       "      <td>487.281212</td>\n",
       "      <td>214.495643</td>\n",
       "      <td>3.157487</td>\n",
       "      <td>730.065995</td>\n",
       "      <td>325.234953</td>\n",
       "      <td>63.019482</td>\n",
       "      <td>84065.558951</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.141519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>27.019733</td>\n",
       "      <td>4.951319</td>\n",
       "      <td>-17.341263</td>\n",
       "      <td>-7.286631</td>\n",
       "      <td>-3.150316</td>\n",
       "      <td>0.010890</td>\n",
       "      <td>101513.0234</td>\n",
       "      <td>101513.0234</td>\n",
       "      <td>213.161011</td>\n",
       "      <td>255.616837</td>\n",
       "      <td>...</td>\n",
       "      <td>487.281212</td>\n",
       "      <td>214.495643</td>\n",
       "      <td>3.157487</td>\n",
       "      <td>730.065995</td>\n",
       "      <td>325.234953</td>\n",
       "      <td>63.019482</td>\n",
       "      <td>84065.558951</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.141519</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>26.516499</td>\n",
       "      <td>5.362008</td>\n",
       "      <td>-17.227922</td>\n",
       "      <td>-7.257047</td>\n",
       "      <td>-2.907396</td>\n",
       "      <td>0.010821</td>\n",
       "      <td>101505.1484</td>\n",
       "      <td>101505.1484</td>\n",
       "      <td>213.188248</td>\n",
       "      <td>255.498810</td>\n",
       "      <td>...</td>\n",
       "      <td>478.439089</td>\n",
       "      <td>207.300143</td>\n",
       "      <td>3.138607</td>\n",
       "      <td>703.124696</td>\n",
       "      <td>325.552442</td>\n",
       "      <td>61.117679</td>\n",
       "      <td>84123.985464</td>\n",
       "      <td>-0.866025</td>\n",
       "      <td>0.5</td>\n",
       "      <td>0.141035</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>5 rows × 52 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "         TMQ      U850       V850      UBOT      VBOT    QREFHT           PS  \\\n",
       "0  25.907482  6.662070 -17.510447 -7.432653 -3.936030  0.010624  101532.5391   \n",
       "1  25.907482  6.662070 -17.510447 -7.432653 -3.936030  0.010624  101532.5391   \n",
       "2  27.019733  4.951319 -17.341263 -7.286631 -3.150316  0.010890  101513.0234   \n",
       "3  27.019733  4.951319 -17.341263 -7.286631 -3.150316  0.010890  101513.0234   \n",
       "4  26.516499  5.362008 -17.227922 -7.257047 -2.907396  0.010821  101505.1484   \n",
       "\n",
       "           PSL        T200        T500  ...  TMQ_WIND850_INTERACTION  \\\n",
       "0  101532.5391  213.092209  256.032043  ...               485.375771   \n",
       "1  101532.5391  213.092209  256.032043  ...               485.375771   \n",
       "2  101513.0234  213.161011  255.616837  ...               487.281212   \n",
       "3  101513.0234  213.161011  255.616837  ...               487.281212   \n",
       "4  101505.1484  213.188248  255.498810  ...               478.439089   \n",
       "\n",
       "   TMQ_WINDBOT_INTERACTION  QREFHT_TREFHT_INTERACTION  TMQ_SQUARE  \\\n",
       "0               217.895122                   3.081385  671.197631   \n",
       "1               217.895122                   3.081385  671.197631   \n",
       "2               214.495643                   3.157487  730.065995   \n",
       "3               214.495643                   3.157487  730.065995   \n",
       "4               207.300143                   3.138607  703.124696   \n",
       "\n",
       "   WIND850_MAGNITUDE_SQUARE  WINDBOT_MAGNITUDE_SQUARE  TREFHT_SQUARE  \\\n",
       "0                350.998912                 70.736668   84123.171146   \n",
       "1                350.998912                 70.736668   84123.171146   \n",
       "2                325.234953                 63.019482   84065.558951   \n",
       "3                325.234953                 63.019482   84065.558951   \n",
       "4                325.552442                 61.117679   84123.985464   \n",
       "\n",
       "   MONTH_SIN  MONTH_COS  LAPSE_RATE  \n",
       "0  -0.866025        0.5    0.143133  \n",
       "1  -0.866025        0.5    0.143133  \n",
       "2  -0.866025        0.5    0.141519  \n",
       "3  -0.866025        0.5    0.141519  \n",
       "4  -0.866025        0.5    0.141035  \n",
       "\n",
       "[5 rows x 52 columns]"
      ]
     },
     "execution_count": 83,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import pandas as pd\n",
    "\n",
    "# Assuming train_data has been previously loaded\n",
    "test_data = pd.read_csv(\"./data/test.csv\")\n",
    "\n",
    "# Format the test_data\n",
    "test_data = format_data(test_data, is_test=True)\n",
    "\n",
    "# List of columns from train_data excluding the label\n",
    "columns_without_label = [col for col in train_data.columns if col != \"Label\"]\n",
    "\n",
    "# Check and add missing columns to test_data and set their values to 0\n",
    "missing_columns = ['SEASON_Spring', 'SEASON_Winter']\n",
    "\n",
    "for col in missing_columns:\n",
    "    if col not in test_data.columns:\n",
    "        test_data[col] = 0\n",
    "\n",
    "# Reorder the columns of test_data to match the order in train_data\n",
    "test_data = test_data[columns_without_label]\n",
    "\n",
    "test_data.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Label 0: 9645 occurrences\n",
      "Label 2: 675 occurrences\n"
     ]
    }
   ],
   "source": [
    "y_test = logisticRegression.predict(test_data)\n",
    "\n",
    "labels, counts = np.unique(y_test, return_counts=True)\n",
    "\n",
    "for label, count in zip(labels, counts):\n",
    "    print(f\"Label {label}: {count} occurrences\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "metadata": {},
   "outputs": [],
   "source": [
    "df = pd.DataFrame({\n",
    "    'SNo': range(1, len(y_test) + 1),\n",
    "    'Label': y_test\n",
    "})\n",
    "\n",
    "df.to_csv(\"logistic_prev.csv\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "kaggle1",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
